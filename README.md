# ğŸ¤ Speech Emotion Recognition using CNN & Mel-Spectrograms

> A deep learning project to classify human emotions (like happy, sad, angry, fearful) from voice signals using Mel-Spectrograms and Convolutional Neural Networks.

This project combines audio feature extraction, CNN-based training, data augmentation, and optional web demo using Gradio.

---

## ğŸ“ Datasets Used

Combined from three open-source emotion speech datasets:

- [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
- [TESS](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)
- [CREMA-D](https://www.kaggle.com/datasets/ejlok1/cremad)

Metadata extracted using a custom script `data_metadata_extractor.py`, resulting in a clean CSV with:
- File path
- Emotion label
- Gender
- Actor ID
- Dataset origin

---

## ğŸ§  Model Architecture

- **Input**: Mel-Spectrogram (grayscale image)
- **Model**: Convolutional Neural Network (CNN)

```text
Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout
      â†“
Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout
      â†“
Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout
      â†“
Flatten â†’ Dense(256) â†’ Dropout â†’ Dense(Num_Classes, softmax)
````

---

## ğŸ› ï¸ Tools & Libraries

* Python, NumPy, Pandas
* TensorFlow / Keras
* Librosa (for Mel-spectrograms)
* Scikit-learn (label encoding, metrics)
* Matplotlib, Seaborn (evaluation plots)
* Gradio (for optional UI)

---

## ğŸ“Š Evaluation

**Test Accuracy**: \~Varied per run
**Note**: Model shows strong training accuracy but overfitting tendencies due to limited compute during training. Validation accuracy can be improved with more balanced data and augmentation.

> âš ï¸ Work in progress to improve generalization and deploy real-time demo.

---

## ğŸ“¦ Project Structure

```
â”œâ”€â”€ metadata/                â† Parsed dataset metadata (CSV)
â”œâ”€â”€ saved_data/              â† Processed features/labels (.npy)
â”œâ”€â”€ model/                   â† Saved model & encoder classes
â”œâ”€â”€ utils/                   â† Preprocessing & helper scripts
â”œâ”€â”€ train.py                 â† Model training pipeline
â”œâ”€â”€ inference.py             â† Load & predict from audio files
â”œâ”€â”€ app.py                   â† Gradio-based prediction UI (optional)
â””â”€â”€ README.md
```

---

## âœ… Features Implemented

* âœ… Multi-dataset integration (RAVDESS, TESS, CREMA-D)
* âœ… Mel-spectrogram-based feature extraction
* âœ… Audio preprocessing & padding
* âœ… Label encoding + one-hot transformation
* âœ… CNN architecture with dropout, batchnorm & callbacks
* âœ… Real-time prediction module & evaluation

---

## ğŸš€ Future Enhancements

* [ ] Add pitch/time-based audio augmentation
* [ ] Improve class balance for edge cases
* [ ] Refactor inference for real-time mic input
* [ ] Deploy Gradio app for public usage
* [ ] Publish on HuggingFace Spaces

---


---

## ğŸ™‹â€â™‚ï¸ About Me

I'm **Neeraj**, a student from India passionate about machine learning and computer vision.

ğŸ“§ Email: [www.asneeraj@gmail.com](mailto:asneeraj@gmail.com)
ğŸ“Œ This project is a part of my AI/ML journey â€” feedback and forks are welcome!

---

## â­ Star This Repo!

If you found this project helpful or inspiring, a â­ would mean a lot and help me grow.
Thanks for visiting! ğŸ˜Š

```

